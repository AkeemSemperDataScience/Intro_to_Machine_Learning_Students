{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.datasets\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (3.1.1)\n",
      "Requirement already satisfied: absl-py in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (1.4.0)\n",
      "Requirement already satisfied: numpy in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: optree in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Download and load the data\n",
    "!pip install keras\n",
    "import keras\n",
    "import os\n",
    "\n",
    "f_path_1 = \"data/diabetes.csv\"\n",
    "url_1 = \"https://github.com/AkeemSemper/ml_data/raw/main/diabetes.csv\"\n",
    "if not os.path.exists(f_path_1):\n",
    "    file_1 = keras.utils.get_file(f_path_1, url_1)\n",
    "df1 = pd.read_csv(f_path_1)\n",
    "\n",
    "f_path_2 = \"data/titanic_train.csv\"\n",
    "url_2 = \"https://github.com/AkeemSemper/ml_data/raw/main/titanic_train.csv\"\n",
    "if not os.path.exists(f_path_2):\n",
    "    file_2 = keras.utils.get_file(f_path_2, url_2)\n",
    "df2 = pd.read_csv(f_path_2)\n",
    "df3 = pd.read_csv(f_path_2)\n",
    "\n",
    "f_path_3 = \"data/Assessments.csv.zip\"\n",
    "url_3 = \"https://github.com/AkeemSemper/ml_data/raw/main/Assessments.csv.zip\"\n",
    "if not os.path.exists(f_path_3):\n",
    "    file_3 = keras.utils.get_file(f_path_3, url_3)\n",
    "df_ = pd.read_csv(f_path_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Sklearn provides a tool for stitching together some of the data preprocessing steps that go into preparing our data, such as encoding categorical variables and rescaling numerical varaibles - the pipeline. \n",
    "\n",
    "The pipeline is concpetually pretty simple, we are just doing the same steps that we'd normally do to perform these data-prep functions. Probably the most challenging change is that the pipeline is more abstract - we don't see each step explicitly laid out, we set them all up and then just get results back. For this reason, it is important that we're comfortable with the ideas as there are fewer steps where we can troubleshoot. \n",
    "\n",
    "The basic process for using a pipeline is:\n",
    "<ul>\n",
    "<li>Create the pipeline object, which is imported from sklearn. \n",
    "<li>Set each preparation step, and the model step as arguments when making the pipeline. \n",
    "<li>Fit the pipeline object (instead of the model) with the data. (The pipeline roughly takes the place of the model)\n",
    "<li>Score and predict with the pipeline object. \n",
    "<li>Documentation is here: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html \n",
    "</ul>\n",
    "\n",
    "For example, we will take our dataset and rescale variables, before using a tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple Pipeline\n",
    "#df1 = pd.read_csv(\"data/diabetes.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a categorical target and some numerical features. \n",
    "\n",
    "The pipeline will be to rescale the features, then train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Split data as normal\n",
    "y = np.array(df1[\"Outcome\"]).reshape(-1,1)\n",
    "X = np.array(df1.drop(columns={\"Outcome\"}))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Sans Pipe\n",
    "scale1 = StandardScaler()\n",
    "X_train_scaled = scale1.fit_transform(X_train)\n",
    "X_test_scaled = scale1.transform(X_test)\n",
    "\n",
    "classifier1 = DecisionTreeClassifier()\n",
    "classifier1.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(classifier1.score(X_test_scaled, y_test))\n",
    "\n",
    "#Build pipeline\n",
    "my_scales = StandardScaler()\n",
    "pipeline_steps = [\n",
    "    ('scaler', my_scales ),\n",
    "    ('DT', DecisionTreeClassifier(max_depth=3))\n",
    "    ]\n",
    "\n",
    "pipe = Pipeline(pipeline_steps)\n",
    "# The pipeline can be used as any other estimator\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Clean and simple!\n",
    "\n",
    "We could do the exact same thing with encoding if we had categorical varaibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex Embarked\n",
       "0         0       3    male        S\n",
       "1         1       1  female        C\n",
       "2         1       3  female        S\n",
       "3         1       1  female        S\n",
       "4         0       3    male        S"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2 = pd.read_csv(\"data/titanic_train.csv\")\n",
    "df2.drop(columns={\"PassengerId\", \"Name\", \"Ticket\", \"Fare\", \"Cabin\", \"Age\", \"SibSp\", \"Parch\"}, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   Survived  891 non-null    category\n",
      " 1   Pclass    891 non-null    category\n",
      " 2   Sex       891 non-null    category\n",
      " 3   Embarked  889 non-null    category\n",
      "dtypes: category(4)\n",
      "memory usage: 4.1 KB\n"
     ]
    }
   ],
   "source": [
    "for i in df2.columns:\n",
    "    df2[i] = df2[i].astype('category')\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026905829596412"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#Split data as normal\n",
    "y = np.array(df2[\"Survived\"]).reshape(-1,1)\n",
    "X = np.array(df2.drop(columns={\"Survived\"}))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#Build pipeline\n",
    "pipeline_steps = [\n",
    "    ('ohe', OneHotEncoder()),\n",
    "    ('DT', DecisionTreeClassifier(max_depth=3))\n",
    "    ]\n",
    "\n",
    "pipe = Pipeline(pipeline_steps)\n",
    "#pipe2 = make_pipeline(OneHotEncoder(), DecisionTreeClassifier())\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Variable Types\n",
    "\n",
    "One thing we didn't handle \"properly\" above was the numerical values, we just dropped them. In order to deal with feature sets that have both categorical (requires encoding) and numerical (requires scaling) we need to use something slightly more complex - the Column Transformer. \n",
    "\n",
    "Our data processing pipeline will usually need to involve several different steps on several different features, some may need to be encoded, others may need to be scaled, and others may need to have missing values dealt with. The Column Transformer is a tool that allows us to split our data processing pipeline into several different paths, and send the appropriate subset of data into each of those paths. \n",
    "\n",
    "We'll look at how we can use a column transformer after a quick detour into one thing we commonly want to use inside of one, imputation..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "\n",
    "One common thing that we need to deal with in processing data for modelling is to handle data that is missing, and extending from the idea of the column transformer it is common that for different features we may need to deal with those missing values differently. Until now we have dealt with any missing data by just deleting the row, so there are no missing values; this action is a simplified version of a process called imputation. Imputation is the general process of filling in missing values. In this data we can see from the Describe that there are 891 rows, but under Age there are some missing values. We could delete these rows, or we could <b><i>impute</i><b> a value to insert as a placeholder - or generate a value to plug in, replacing the missing value. This allows us to keep those rows that have a missing value. \n",
    "\n",
    "Imputation is a very common data preparation step, it takes blank data and \"deals with it\". Dealing with it may mean removing those blanks, or using some more advanced analysis to determine a placeholder value to insert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df3 = pd.read_csv(\"data/titanic_train.csv\")\n",
    "df3.drop(columns={\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"}, inplace=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std   min      25%      50%   75%       max\n",
       "Survived  891.0   0.383838   0.486592  0.00   0.0000   0.0000   1.0    1.0000\n",
       "Pclass    891.0   2.308642   0.836071  1.00   2.0000   3.0000   3.0    3.0000\n",
       "Age       714.0  29.699118  14.526497  0.42  20.1250  28.0000  38.0   80.0000\n",
       "SibSp     891.0   0.523008   1.102743  0.00   0.0000   0.0000   1.0    8.0000\n",
       "Parch     891.0   0.381594   0.806057  0.00   0.0000   0.0000   0.0    6.0000\n",
       "Fare      891.0  32.204208  49.693429  0.00   7.9104  14.4542  31.0  512.3292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "blank_rows = df3['Age'].isnull().sum()\n",
    "print(blank_rows)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Considerations\n",
    "\n",
    "The positive to doing this imputation is that we don't loose data. In many real world scenarios we often have some data that is missing. Think about a scenario where we are attempting to predict if people will get skin cancer - our features may be things like where they live, sun exposure, outdoor jobs, tanning, race/skin color, medical info, etc... In a real world study it is pretty difficult to gather a large dataset where every useful feature can be captured for every row in the dataset. Deleting every row where we have any missing value would likely cut our large, and hard and expensive to gather data, down to a shell of itself - if we did a large cancer study that spanned years, we probably wouldn't want to delete patients if they failed to complete one survey question. By imputing those missing values we can keep our valuable data by plugging in some placeholder for those occasional missing spots. \n",
    "\n",
    "For this example, we are plugging in an average (mean) age for the rows of Titanic-ers for which we have no age. This seems somewhat reasonable based on intuition - if there is some random passenger and we have no idea of their age, but we assume they are ~30, that probably doesn't mess things up too dramatically. There's a possibility that they are really old and we are way off, but the 75% percentile is 38, so the odds of that are pretty low. Overall we are probably 'winning' by keeping all that other data by using the imputation of age. \n",
    "\n",
    "The negative is that we are literally inventing a new value, and plugging it in - we are making up fake data. This can obviously introduce error if we do it poorly. For example, assume we are examining stock market data to predict stock price increases, to determine if we should invest. Imputing profitability (earnings per share) may not be super logical in this scenario. \n",
    "\n",
    "#### Why is it Missing?\n",
    "\n",
    "One key consideration in the real world in doing imputation is examining why the data is missing. Is the data just randomly missing, or is there some reason why some values may be missing?\n",
    "\n",
    "For example, survey data that involves people self-identifying with/as something that may incur discrimination (lgbt, race, disability, age) are commonly underidentified. Collecting data may be more challenging in remote environments vs cities. Forms may be poorly laid out, leading to one question being consistently overlooked. \n",
    "\n",
    "There are a lot of reasons that values may be missing, and examination with domain knowledge will help us determine the most appropriate imputation strategy. We will look at more sophisticated imputation stuff later on. \n",
    "\n",
    "#### Imputation Overall and Initial Strategy\n",
    "\n",
    "Imputation is extremely common in machine learning. In the smaller test datasets that we often use it isn't as important, as these tend to be more complete. In real world scenarios, especially when data is hard to collect (e.g. census, suveys, etc...), it is pretty common and often required to maintain the usability of our datasets. \n",
    "\n",
    "#### Imputation Approach\n",
    "\n",
    "For now, we can focus on simple imputation:\n",
    "\n",
    "<ul>\n",
    "<li>Numerical Imputation:\n",
    "<ul>\n",
    "<li>Replace with median: If we want to maintain median - outliers, skewed distributions such as income. \n",
    "<li>Replace with mean: If we want to maintain mean - normal(ish) distributions such as height. \n",
    "</ul>\n",
    "<li>Categorical Imputation:\n",
    "<ul>\n",
    "<li>Replace with mode (most common value)\n",
    "</ul>\n",
    "<li>Either:\n",
    "<ul>\n",
    "<li>If there is some default value, we can fill with a constant. For example, if you have data on number of citizenships that people have, the vast majority have 1. It makes sense to impute 1 if that data is missing (in this case that's the mode). \n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "There are several more complex imputation techniques that can be used, we'll look at some briefly when we look at clustering. The basic idea behind all of them is that they seek to impute a value that is \"better\" than one of the simple guesses by using the other data to come up with a more targeted value to impute. For example, if we were imputing a value for someone's income, and we knew their profession, it would likely make sense to impute a different value for the income of a brain surgeon than for a parking lot attendant. \n",
    "\n",
    "One more consideration is the number of missing values in a column - if we are just imputing a huge percentage of the values for one of our features, that feature probably isn't helping us all that much. A rule of thumb is that if you're missing about 20%-30% of the values in a column it is better to just drop that column rather than impute values for it. This rule of thumb is pretty loose - it really requires a specific look at the data, mainly the reason that values are missing. If we can infer some meaning from what's missing, we are more likely to be able to determine a logical imputation. In this Titanic example, Age is missing in a large number of rows, but keeping it is still worth it because the imputation is reasonable. \n",
    "\n",
    "Lastly, fillna in pandas also imputes similarly to what we are doing here. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines with Column Transformers\n",
    "\n",
    "Our goal here is to create a pipleine to do the following:\n",
    "<ul>\n",
    "<li>Impute missing numeric values with the mean. \n",
    "<li>Scale numeric values with a standard scaler. \n",
    "<li>Encode categorical values.\n",
    "<li>Model with a decision tree. \n",
    "</ul>\n",
    "\n",
    "The column transformer object allows us to split the features that we are processing and deal with each group separately, this is very common in situations where we have both numeric and categorical variables to prepare - the numeric variables can be scaled, the categorical ones can be encoded, then they can be recombined into our prepared dataset.\n",
    "\n",
    "![Column Transformer](images/col_trans.png \"Column Transformer\")\n",
    "\n",
    "### Using a Column Transformer\n",
    "\n",
    "A column transformer functions like a slightly more elaborate pipeline:\n",
    "<ul>\n",
    "<li> The column transformer takes in multiple data subsets, and preprocessing pipelines. \n",
    "    <ul>\n",
    "    <li> Each argument in creating the CT contains 3 things - an informal label, the columns to process, and a pipeline of the processing steps. \n",
    "    </ul>\n",
    "<li> Each subset flows through the supplied processing pipeline. \n",
    "<li> At the end, the data is recombined, and the data is spit out ready for modelling. \n",
    "<li> In general, when using a column transformer, we will have:\n",
    "    <ul> \n",
    "    <li> A column transformer that is effectively \"the preprocessing pipeline\". \n",
    "    <li> Within that transformer, a pipeline that deals with each distinct subset of data (usually one for categorical, one for numerical).\n",
    "    <li> Another pipeline with two steps - the column transformer and the model, this is what we call \"fit\" on. \n",
    "    </ul>\n",
    "</ul>\n",
    "<b>Note:</b> we can split the columns into our groups in the column transformer either by manual inspection, or by some automatic filter like the data type. If you're automating it, make sure that you can trust that the data types are trustworthy - something like a rouge \"n/a\" in a numerical column could mess everything up. Some commands that can get the data types are df.dtypes, df.select_dtypes, and df.columns.\n",
    "\n",
    "This all sounds a bit complex, but it isn't much worse than setting up a pipeline, here we've just layered in another step and we need to split the data into subsets. The steps like fit and score that we are used to with pipelines or models all work the same once the column transformer is established. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = [\"Age\", \"Fare\"]\n",
    "numeric_transformer = Pipeline( steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "numeric_features2 = [\"SibSp\", \"Parch\"]\n",
    "numeric_transformer2 = Pipeline( steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_features = [\"Embarked\", \"Sex\", \"Pclass\"]\n",
    "categorical_transformer = Pipeline( steps=[\n",
    "    (\"one_hot\", OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer( transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"numeric_2\", numeric_transformer2, numeric_features2)\n",
    "    ])\n",
    "#Build pipeline\n",
    "pipeline_steps = [('pre', preprocessor),('DT', DecisionTreeClassifier()) ]\n",
    "pipe = Pipeline(pipeline_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the column transformer is created, putting it to use is a familiar process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757847533632287"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split data as normal\n",
    "y = df3[\"Survived\"]\n",
    "X = df3.drop(columns={\"Survived\"})\n",
    "\n",
    "#Build pipeline\n",
    "#pipeline_steps = [('pre', preprocessor),('DT', DecisionTreeClassifier()) ]\n",
    "#pipe = Pipeline(pipeline_steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Pipeline Objects\n",
    "\n",
    "As you may have picked up on, there's a lot of interchangeability between the sklearn objects that we use to prepare and model data. This is generally good, as we can arrange the exact pieces that we need and they'll work together in almost any combination. This can also be a little confusing, as there's not one fixed way to do things. In the long run, we'll get more used to this and be able to use it to our advantage - as long as something fits the template of these preprocessing tools (there are specific classes to extend, we'll look at it a little more later on) we can plug and play different preprocessing items, and even create our own. \n",
    "\n",
    "The ability to swap things in and out will be useful soon when we look at a grid search - the interchangability of steps helps allow us to automate the running of different trials to see what is most accurate. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Predict the Target\n",
    "\n",
    "Think about processing the different types of data, how to deal with missing values, and how to encode the categorical variables.\n",
    "\n",
    "<b>Note:</b> the OneHotEncoder is used to encode the categorical variables in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Number</th>\n",
       "      <th>Suite</th>\n",
       "      <th>House Number</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Neighbourhood ID</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1066158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14904.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.630497</td>\n",
       "      <td>-113.580474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16340.0</td>\n",
       "      <td>MARK MESSIER TRAIL NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>53.617335</td>\n",
       "      <td>-113.605690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1194398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15617.0</td>\n",
       "      <td>83 STREET NW</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>BELLE RIVE</td>\n",
       "      <td>Ward 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.617007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1034214.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10661.0</td>\n",
       "      <td>161 AVENUE NW</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>BEAUMARIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>635000.0</td>\n",
       "      <td>53.619978</td>\n",
       "      <td>-113.506990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1114701.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76 AVENUE NW</td>\n",
       "      <td>4430.0</td>\n",
       "      <td>RIO TERRACE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407500.0</td>\n",
       "      <td>53.508644</td>\n",
       "      <td>-113.579897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Account Number Suite  House Number            Street Name  \\\n",
       "0       1066158.0   NaN       14904.0                    NaN   \n",
       "1             NaN   NaN       16340.0  MARK MESSIER TRAIL NW   \n",
       "2       1194398.0   NaN       15617.0           83 STREET NW   \n",
       "3       1034214.0   NaN       10661.0          161 AVENUE NW   \n",
       "4       1114701.0   NaN           NaN           76 AVENUE NW   \n",
       "\n",
       "   Neighbourhood ID Neighbourhood    Ward  Assessed Value   Latitude  \\\n",
       "0               NaN           NaN     NaN             NaN  53.630497   \n",
       "1               NaN           NaN     NaN         45000.0  53.617335   \n",
       "2            2050.0    BELLE RIVE  Ward 3             NaN  53.617007   \n",
       "3            3040.0     BEAUMARIS     NaN        635000.0  53.619978   \n",
       "4            4430.0   RIO TERRACE     NaN        407500.0  53.508644   \n",
       "\n",
       "    Longitude  target  \n",
       "0 -113.580474       0  \n",
       "1 -113.605690       0  \n",
       "2         NaN       0  \n",
       "3 -113.506990       1  \n",
       "4 -113.579897       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeReadyToImpute(df_):\n",
    "    # Calculate the number of cells in the DataFrame\n",
    "    num_cells = df_.size\n",
    "    # Calculate 10% of the number of cells\n",
    "    num_del = int(num_cells * 0.1)\n",
    "    # Create a DataFrame of the same shape as df_ and fill it with True values\n",
    "    mask = pd.DataFrame(True, index=df_.index, columns=df_.columns)\n",
    "    # Select a random sample of cells\n",
    "    cells_to_del = mask.stack().sample(n=num_del).index\n",
    "    # Set the selected cells to NaN\n",
    "    for idx in cells_to_del:\n",
    "        df_.at[idx] = np.nan\n",
    "    return df_\n",
    "#df_ = pd.read_csv(\"data/Assessments.csv\")\n",
    "#df_.rename(columns={\"Garage\":\"target\"}, inplace=True)\n",
    "targets = np.where(df_[\"Garage\"] == \"Y\", 1, 0)\n",
    "df_.drop(columns={\"Garage\"}, inplace=True)\n",
    "df_ = makeReadyToImpute(df_)\n",
    "df_[\"target\"] = targets\n",
    "df_[\"target\"].dropna(inplace=True)\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Column Transformer and Model\n",
    "\n",
    "Try to swap out a model, or some of the other steps, and see how different the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors - kNN\n",
    "\n",
    "k-Nearest Neighbors, or kNN, is a <b>supervised</b> machine learning algorithm that we can use for both regression and classification. This <b>is not</b> the same as k-means clustering nor is it directly related, it is conceptually similar though, so we'll take a quick peek at it here. We won't examine kNN in depth. \n",
    "\n",
    "The basic idea of kNN is that things that are similar are \"close\" to each other. The algorithm functions like this:\n",
    "\n",
    "<ol>\n",
    "<li> Select the number K of the neighbors\n",
    "<li> Calculate the Euclidean distance of K number of neighbors\n",
    "<li> Take the K nearest neighbors as per the calculated Euclidean distance.\n",
    "<li> Among these k neighbors, count the number of the data points in each category.\n",
    "<li> Assign the new data points to that category for which the number of the neighbor is maximum.\n",
    "<li> Our model is ready.\n",
    "</ol>\n",
    "\n",
    "![kNN](images/knn.png \"kNN\" )\n",
    "\n",
    "Implementation in sklearn is pretty similar to other modelss. \n",
    "\n",
    "kNN is relatively simple, but can get slow with large volumes of data and is often surpassed in performance by other models, so we don't see it used all that much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "model_knn_class = KNeighborsClassifier()\n",
    "model_knn_reg = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Imputation\n",
    "\n",
    "One place where kNN is very useful is in doing imputation. When we have done imputation, we've gone with something simple, like the mean or median, or the mode for the most frequent value. This is easy, but has some obvious weaknesses. Suppose we are imputing something like income for census type data. Taking the median income for a random missing income value may be OK, but people tend to have pretty different incomes. What if instead of just taking the overall average, we took the average of the nearest neighbors - in this case potentially, literal neighbors. \n",
    "\n",
    "KNNImputer is an imputation method that does just that, each record will \"find its neighbors\" based on similarity on the other metrics, and that subset of records will be averaged and imputed. In this example, we may impute by finding people with similar location, home size, career, etc... and taking their average, which makes more sense intuitively and can often be more accurate. Using this smarter imputation will often improve our ability to make useful imputations when data is missing, the exact impact depends on the data, but it is something that is certainly worth a try. \n",
    "\n",
    "![KNN Imputation](images/knnImpute.png \"KNN Imputation\" )\n",
    "\n",
    "In the image above, if we were imputing a class, we would take the most common class of the nearest neighbors inside that \"K\" circle. For a number, we'd average those records together. Another sklearn package, IterativeImputer, does a similar thing using regression. See sklearn documentation for details, use is simple, just like other imputers.\n",
    "\n",
    "A demo of smarter imputation can be seen easily in a really simple example. The values in the <b>top right</b> and the <b>first row, 2nd from bottom</b> are imputed differently with each imputer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "nan = np.nan\n",
    "X = [[1, 0, nan], [7, 4, 0], [nan, 8, 5], [9, 8, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_imp = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "sns.heatmap(knn_imp.fit_transform(X), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYkAAAKcCAYAAACt9zWKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOuxJREFUeJzt3Xm8lXW5N/7PZthADIoDYHqUScQJRXHgaDigVA6VppkHM03NoaPmPFWYqJgilWapZXFOjqVF+bNS4UkzM8WBylBENHICBBVExs1azx/+5Jz9OLQYb/e6329f+2V8b+7vuvrDcl989nU1VKvVagAAAAAAKKVWRRcAAAAAAEBxNIkBAAAAAEpMkxgAAAAAoMQ0iQEAAAAASkyTGAAAAACgxDSJAQAAAABKTJMYAAAAAKDENIkBAAAAAEpMkxgAAAAAoMQ0iQEAAAAAWqj58+dnxIgR2X333bPzzjvnzDPPzJw5c1boDk1iAAAAAIAW6tRTT83999+fSy65JDfddFMWLlyYI488MkuWLKn5Dk1iAAAAAIAW6Kmnnsof//jHXHTRRdljjz2y+eab5/LLL8+sWbNy11131XyPJjEAAAAAQAv0j3/8I0kyaNCg5WcdO3bMZpttlkceeaTme9qs7sIAAAAAAKjd0KFDP/D5hAkT3vO8W7duSZJXXnklffr0SZIsW7YsM2bMyPrrr1/z538om8Rbd9+l6BIAKJEpr79YdAkAlMSvug4pugQASmL/mbcUXUKLtHT2c0WXsEK23Xbb9O7dOyNGjMiVV16ZddZZJ1dddVVef/31LF26tOZ7PpRNYgAAAACAsni/pPC/0tjYmO9973s5++yzM2TIkLRt2zYHHnhg9tprr7RqVfukYU1iAAAAAIAkqSwruoIV1qdPn9xxxx1544030qZNm3Tq1CmHHHJIdt1115rvsLgOAAAAAKAFmj9/fo444og8/fTTWXfdddOpU6e8+OKLmTx5cnbbbbea79EkBgAAAABogTp16pRqtZpLLrkkU6dOzd/+9receOKJ2XXXXTN48OCa79EkBgAAAABIkmqlmK9VMGbMmKyzzjo5/PDDc/zxx2fHHXfM1VdfvUJ3mEkMAAAAANBCde/ePd/73vdW6Q5NYgAAAACAJKmsWqq3pTJuAgAAAACgxCSJAQAAAACSVFdxPnBLJUkMAAAAAFBimsQAAAAAACVm3AQAAAAAQGJxHQAAAAAA5SNJDAAAAACQJBbXAQAAAABQNprEAAAAAAAlZtwEAAAAAECSVJYVXUEhJIkBAAAAAEpMkhgAAAAAILG4DgAAAACA8pEkBgAAAABIkookMQAAAAAAJaNJDAAAAABQYsZNAAAAAAAkqVpcBwAAAABA2UgSAwAAAAAkFtcBAAAAAFA+msQAAAAAACVm3AQAAAAAQJJYXAcAAAAAQNlIEgMAAAAAJEllWdEVFEKSGAAAAACgxCSJAQAAAAASM4kBAAAAACgfTWIAAAAAgBIzbgIAAAAAIEkqxk0AAAAAAFAyksQAAAAAAInFdQAAAAAAlI8mMQAAAABAiRk3AQAAAACQWFwHAAAAAED5SBIDAAAAACSpVpcVXUIhJIkBAAAAAEpMkxgAAAAAoMSMmwAAAAAASJKqxXUAAAAAAJSMJDEAAAAAQJJUJIkBAAAAACgZSWIAAAAAgMRMYgAAAAAAykeTGAAAAACgxIybAAAAAABIksqyoisohCQxAAAAAECJSRIDAAAAACQW1wEAAAAAUD6axAAAAAAAJWbcBAAAAABAklSMmwAAAAAAoGQkiQEAAAAAEovrAAAAAAAoH0liAAAAAIDETGIAAAAAAFqWpqamfPe7381ee+2VgQMHZvjw4Zk0adIK3aFJDAAAAADQQv3gBz/Iz3/+84wcOTLjxo1Lr169cuyxx2bWrFk136FJDAAAAACQvD1uooivVTB+/PgccMAB2X333bPZZpvl3HPPzZtvvrlCaWJNYgAAAACAFmr99dfP73//+7z44otZtmxZbrvttjQ2NqZ///4132FxHQAAAABAkmp1WSGfO3To0A98PmHChPd9dsEFF+TUU0/N0KFD07p167Rq1SpXX311Nt1005o/X5IYAAAAAKCFevbZZ9O5c+dcc801ue2223LwwQfnzDPPzFNPPVXzHZLEAAAAAAAF+qCk8Ad55ZVXcsYZZ2Ts2LEZNGhQkmTbbbfNs88+m6uvvjrf//73a7pHkhjqSPeNuuWhZ8Znp3/foehSAKhT++4zJA/96a7Me+PZTJ3yUE4/7fiiSwKgBHb88WnZa+JVRZcBlEELW1z3l7/8JUuXLs22227b7Hy77bbL9OnTa75HkxjqRI+PdssPb7sqXdbpXHQpANSpXXbeIb8a91+ZMmVaDv3csbnl1l/mslFfy9lnfaXo0gCoYxt/dvf02H/nossA+FDq0aNHkmTKlCnNzp955pn07Nmz5nuMm4AWrqGhIZ/+3H45c8QpaWhoKLocAOrYiG+ckUmTnsxRR5+SJLn7nvvStm2bnHvOybnq6huyaNGigisEoN606941W13yxSx8aU7RpQBlUV35VG8RBgwYkB133DHnnHNORowYkR49emTcuHF56KGHcsstt9R8jyQxtHBbbNU337j8nPz657/Juf95YdHlAFCnGhsbs8cegzPuV79rdn7HHXelS5fO2X23nQqqDIB6NmDMcZl9/18z+4Eniy4F4EOpVatW+cEPfpBdd9015513Xg4++OD8+c9/ztixY7PddtvVfI8kMbRwr7w0M5/c9ZDMfGWWWcQArDG9e2+adu3a5ZmpzzU7f3baP5Ik/fr1yfgJDxRQGQD16t+G75V1tuud+4eclS1HDC+6HKAsVmE+cFHWWWedjBgxIiNGjFjpO1aoSdzU1JR77rknEydOzCuvvJIlS5akQ4cO6d69e3baaacMGzYsrVu3XuligBU39415mfvGvKLLAKDOrdOlS5LkzXnzm52/+ebbv+7SxUx8AFafDptskC2/eUT+eup1Wfram0WXA1D3ah438eKLL2b//ffP+eefnylTpqR9+/bZcMMN07Zt2zz99NM577zzcuCBB+bll19ek/UCAFCAVq0++F8bKy0wcQHAh9eA7xyfVydMyoy7Him6FIBSqDlJfNFFF2WTTTbJ7bffns6d350UmTdvXk477bRcdNFFufbaa1drkQAAFGvuvLd/aqVT547Nzt9JEM+dK+UFwOqx2ZeGpfOWm+aBPc9OQ+u3/5DynSXdDa1bpVqpJtVqkSUC9ayFLa5bXWpuEk+cODG33nrrezaIk6RLly4566yzMny4OUEAAPVm2rTpaWpqSt8+PZudv/Prp5+euvaLAqAubXTALmm3QZfs8+S7A2j7vXxTnrni9kwdfUcBlQHUr5qbxJ07d87MmTOzxRZbvO/vefnll9O+ffvVUhgAAB8eixcvzgMPPJyDPrNfrhzzP9+0H3zwfnnjjbl5ZOITBVYHQD3521k/SptOHZqdbX7mwVlnQO88euToLJrxekGVAaVQ0jFqNTeJDznkkJx77rk59dRTs+uuu2ajjTZKY2NjlixZkpkzZ+aRRx7J6NGjc8ghh6zJegEAKMilo76bu393a2695bqMHXtrBg8elDNOPzHnX3BpFi5cVHR5ANSJt6a98q6zJa/NT2VJU+b+5bkCKgKofzU3iU8++eS0atUql19+eRYsWPCu5x07dszw4cNz6qmnrtYCAQD4cPj9fQ/m0MOOy4hvnJE7br8hL700I+ece3G+/Z3rii4NAABYBQ3V6opNe1+6dGmeeuqpzJw5MwsXLkz79u3To0eP9O/fP42NjaulqK2777Ja7gGAWkx5/cWiSwCgJH7VdUjRJQBQEvvPvKXoElqkhXd/r5DP7fDx/yzkc99Rc5L4HW3bts2AAQPWRC0AAAAAAKxlK9wkBgAAAACoSyVdXNeq6AIAAAAAACiOJDEAAAAAQCJJDAAAAABA+WgSAwAAAACUmHETAAAAAABJUjVuAgAAAACAkpEkBgAAAABILK4DAAAAAKB8NIkBAAAAAErMuAkAAAAAgMTiOgAAAAAAykeSGAAAAAAgsbgOAAAAAIDykSQGAAAAAEjMJAYAAAAAoHw0iQEAAAAASsy4CQAAAACAxOI6AAAAAADKR5IYAAAAACCRJAYAAAAAoHw0iQEAAAAASsy4CQAAAACAJKlWi66gEJLEAAAAAAAlJkkMAAAAAJBYXAcAAAAAQPlIEgMAAAAAJJLEAAAAAACUjyYxAAAAAECJGTcBAAAAAJAkVeMmAAAAAAAoGUliAAAAAIDE4joAAAAAAMpHkxgAAAAAoMSMmwAAAAAASJJqtegKCiFJDAAAAABQYpLEAAAAAACJxXUAAAAAAJSPJjEAAAAAQIkZNwEAAAAAkBg3AQAAAABA+UgSAwAAAAAkSVWSGAAAAACAkpEkBgAAAABIUq1Uiy6hEJLEAAAAAAAlpkkMAAAAAFBixk0AAAAAACRJxeI6AAAAAABKRpIYAAAAACBJqi0rSfzwww/nyCOPfM9nm2yySSZMmFDTPZrEAAAAAAAt0MCBA/PHP/6x2dmkSZNy8skn56STTqr5Hk1iAAAAAIAWqLGxMRtuuOHyXy9YsCCjRo3KQQcdlM9+9rM136NJDAAAAACQJJVq0RWskmuvvTYLFy7MOeecs0LvaRIDAAAAABRo6NChH/i8ltnCr732WsaOHZszzjgj66677gp9viYxAAAAAECSVFrW4rr/7eabb07nzp1z2GGHrfC7msQAAAAAAAWqJSn8r4wbNy6f+cxn0r59+xV+V5MYAAAAACBpsUnip59+Oi+88EIOPPDAlXq/1WquBwAAAACAtejRRx/N+uuvn/79+6/U+5rEAAAAAAAt2OTJk7PFFlus9PvGTQAAAAAAJEm1WnQFK+XVV1/Nuuuuu9LvaxIDAAAAALRgP/zhD1fpfU1iAAAAAICkxS6uW1VmEgMAAAAAlJgmMQAAAABAiRk3AQAAAACQJJWWubhuVUkSAwAAAACUmCQxAAAAAECSVC2uAwAAAACgZCSJAQAAAAASM4kBAAAAACgfTWIAAAAAgBL7UI6bmPiNnYouAYAS+f1FvYsuAYCS+PTrfyi6BABKoqnoAlqoasXiOgAAAAAASuZDmSQGAAAAAFjrLK4DAAAAAKBsNIkBAAAAAErMuAkAAAAAgCSpWlwHAAAAAEDJSBIDAAAAACQW1wEAAAAAUD6SxAAAAAAASVIxkxgAAAAAgJLRJAYAAAAAKDHjJgAAAAAAEovrAAAAAAAoH0liAAAAAIAkqVpcBwAAAABAyWgSAwAAAACUmHETAAAAAACJxXUAAAAAAJSPJDEAAAAAQJJqxeI6AAAAAABKRpIYAAAAACAxkxgAAAAAgPLRJAYAAAAAKDHjJgAAAAAAEuMmAAAAAAAoH0liAAAAAIAkqVaKrqAQksQAAAAAACWmSQwAAAAAUGLGTQAAAAAAJBbXAQAAAABQPpLEAAAAAABJqpLEAAAAAACUjSQxAAAAAEBiJjEAAAAAAOWjSQwAAAAAUGLGTQAAAAAAJEmlUnQFhZAkBgAAAAAoMUliAAAAAIDE4joAAAAAAMpHkxgAAAAAoMSMmwAAAAAASIybAAAAAACgfCSJAQAAAACSVKuSxAAAAAAAlIwmMQAAAABAiWkSAwAAAAAkby+uK+JrFY0bNy777bdftt122+y///757W9/u0LvaxIDAAAAALRQv/rVr3LBBRdk+PDhueuuu3LAAQfk9NNPzxNPPFHzHRbXAQAAAAAkqyXVuzZVq9V897vfzZFHHpnhw4cnSU488cQ8+uijeeSRRzJw4MCa7tEkBgAAAABogZ5//vm89NJLOfDAA5ud33DDDSt0jyYxAAAAAECSakFJ4qFDh37g8wkTJrzn+fPPP58kWbBgQY455phMnjw5m2yySU488cTsvffeNX++mcQAAAAAAC3Q/PnzkyTnnHNODjjggPz4xz/ObrvtlpNOOikPPfRQzfdIEgMAAAAAFOj9ksL/Stu2bZMkxxxzTA466KAkyZZbbpnJkyfnJz/5SQYPHlzTPZLEAAAAAADJ24vrivhaSd27d0+S9OvXr9l537598+KLL9Z8jyYxAAAAAEALtPXWW6djx475y1/+0uz8mWeeyaabblrzPcZNAAAAAAAkSaXoAlZM+/btc+yxx+aaa65J9+7dM2DAgNx111158MEHM3bs2Jrv0SQGAAAAAGihTjrppHTo0CHf/va3M3PmzPTp0ydXX311dtlll5rv0CQGAAAAAGjBjj766Bx99NEr/b4mMQAAAABAkuoqLJFrySyuAwAAAAAoMUliAAAAAIAkkSQGAAAAAKBsJIkBAAAAAJKkUnQBxZAkBgAAAAAoMU1iAAAAAIASM24CAAAAACBJ1eI6AAAAAADKRpIYAAAAACCxuA4AAAAAgPLRJAYAAAAAKDHjJqAFe/TF13LcLx573+cn7NI7x+/SZy1WBECZ7Pjj09Jl2175/U6nFF0KAHVq332G5KKLzsnWW22RmTNfzQ+uHZsx376u6LKAOlbWxXWaxNCC9d+wS/7r0J3edX7Nn6dl8sx5+US/HgVUBUAZbPzZ3dNj/52z4J+vFl0KAHVql513yK/G/Vd+9vM7c+GFV2S33XbOZaO+ljZt2uTyK64pujyAuqJJDC1Yp3ZtMmCjdZud3ffcrDzywmu5/JMDslnXjsUUBkBda9e9a7a65ItZ+NKcoksBoI6N+MYZmTTpyRx19Ns/sXL3Pfelbds2Ofeck3PV1Tdk0aJFBVcI1CWL64CWblHTsnzr/in5WM8Nsu/m3YsuB4A6NWDMcZl9/18z+4Eniy4FgDrV2NiYPfYYnHG/+l2z8zvuuCtdunTO7ru9+ycqAVh5msRQR26e9M+8On9xzhyyRdGlAFCn/m34Xllnu9558ryxRZcCQB3r3XvTtGvXLs9Mfa7Z+bPT/pEk6dfP7hVgzahWivkqmnETUCeWLqvklkn/zMf7dc+m636k6HIAqEMdNtkgW37ziPz11Ouy9LU3iy4HgDq2TpcuSZI3581vdv7mm2//ukuXzmu9JoB6JkkMdWL8szMze8GSHLlDz6JLAaBODfjO8Xl1wqTMuOuRoksBoM61avXB7YpK5UMQuwOoI5LEUCfGPzsrfdbrmC029CfqAKx+m31pWDpvuWke2PPsNLR++xv3hoaGt//eulWqlWpSrRZZIgB1ZO68eUmSTp2bL+N+J0E8d66faAHWkJL+GdQKNYm/8IUvLP9m4F/57//+75UqCFhxS5dV8qfps3PUjj2LLgWAOrXRAbuk3QZdss+T177r2X4v35Rnrrg9U0ffUUBlANSjadOmp6mpKX379Gx2/s6vn3566tovCqCOrVCTePfdd893v/vd9OrVKwMGDFhTNQEr6Nk587OoqZLtP7pu0aUAUKf+dtaP0qZTh2Znm595cNYZ0DuPHjk6i2a8XlBlANSjxYsX54EHHs5Bn9kvV475nz+gPPjg/fLGG3PzyMQnCqwOqGcfhiVyRVihJvHxxx+fTp065corr8x1112XTTbZZE3VBayAqXPeXt7Qe71OBVcCQL16a9or7zpb8tr8VJY0Ze5fnnuPNwBg1Vw66ru5+3e35tZbrsvYsbdm8OBBOeP0E3P+BZdm4cJFRZcHUFdWeHHd8OHDs/POO+fyyy9fE/UAK+G1BUuSJF3aGTMOAADUh9/f92AOPey49OvXO3fcfkMO//xBOefcizP6yh8UXRpA3WmoVld8w8isWbPy97//PXvttdeaqCkLrvnPNXIvALyX3180p+gSACiJT7/+h6JLAKAkmpa8VHQJLdLsj+9RyOducPf9hXzuO1YqdtitW7d069ZtddcCAAAAAMBa5mfTAQAAAABS3sV1KzyTGAAAAACA+iFJDAAAAAAQSWIAAAAAAEpIkxgAAAAAoMSMmwAAAAAAiHETAAAAAACUkCQxAAAAAECSVBuKrqAQksQAAAAAACWmSQwAAAAAUGLGTQAAAAAAxOI6AAAAAABKSJIYAAAAACBJtWJxHQAAAAAAJSNJDAAAAAAQM4kBAAAAACghTWIAAAAAgBIzbgIAAAAAIEm1anEdAAAAAAAlI0kMAAAAABCL6wAAAAAAKCFNYgAAAACAEjNuAgAAAAAgSbVicR0AAAAAACUjSQwAAAAAkKRaLbqCYkgSAwAAAACUmCQxAAAAAEDMJAYAAAAAoIQ0iQEAAAAASsy4CQAAAACAGDcBAAAAAEAJSRIDAAAAACSpVouuYMXNnDkzQ4YMedf5qFGjcvDBB9d0hyYxAAAAAEAL9fTTT6ddu3YZP358Ghr+Z1xG586da75DkxgAAAAAoIV65pln0rNnz3Tr1m2l79AkBgAAAABIy1xcN2XKlPTp02eV7tAkBgAAAAAo0NChQz/w+YQJE9732TPPPJOuXbtm+PDhef7557PZZpvlxBNPfM85xe+nVc2/EwAAAACgjlWrDYV8raympqY899xzmTt3bk4++eRcf/312X777fPlL385Dz30UM33SBIDAAAAABTog5LCH6RNmzZ5+OGH07p167Rv3z5Jss0222Tq1Km54YYbMnjw4JrukSQGAAAAAGihOnbsuLxB/I7NN988M2fOrPkOTWIAAAAAgCTVSjFfK2vq1KnZYYcd8vDDDzc7f/LJJ9O3b9+a79EkBgAAAABogfr06ZPevXvnoosuyqOPPppp06Zl1KhRmTRpUk488cSa7zGTGAAAAAAgSWUVlsgVoVWrVrn22mtz5ZVX5qtf/WrmzZuXrbbaKj/5yU/Sr1+/mu/RJAYAAAAAaKE22GCDjBo1apXu0CQGAAAAAEhSbWFJ4tXFTGIAAAAAgBLTJAYAAAAAKDHjJgAAAAAAklQrxk0AAAAAAFAyksQAAAAAAEmq1aIrKIYkMQAAAABAiWkSAwAAAACUmHETAAAAAACxuA4AAAAAgBKSJAYAAAAASFKpShIDAAAAAFAyksQAAAAAAEmqksQAAAAAAJSNJjEAAAAAQIkZNwEAAAAAkKRaLbqCYkgSAwAAAACUmCQxAAAAAECSisV1AAAAAACUjSYxAAAAAECJGTcBAAAAAJCkatwEAAAAAABlI0kMAAAAAJCkWi26gmJIEgMAAAAAlJgkMQAAAABAkoqZxAAAAAAAlI0mMQAAAABAiX0ox00suudvRZcAQIns/fOjiy4BgJJ45itzii4BAPgAVeMmAAAAAAAomw9lkhgAAAAAYG2zuA4AAAAAgNLRJAYAAAAAKDHjJgAAAAAAklSLLqAgksQAAAAAACUmSQwAAAAAEIvrAAAAAAAoIUliAAAAAIAkVUliAAAAAADKRpMYAAAAAKDEjJsAAAAAAEhSKbqAgkgSAwAAAACUmCQxAAAAAECSaiyuAwAAAACgZDSJAQAAAABKzLgJAAAAAIAklWrRFRRDkhgAAAAAoMQkiQEAAAAAklQsrgMAAAAAoGwkiQEAAAAAklQliQEAAAAAKBtNYgAAAACAEjNuAgAAAAAgSaXoAgoiSQwAAAAAUGKSxAAAAAAAsbgOAAAAAIAS0iQGAAAAACgxTWIAAAAAgLy9uK6Ir9Xl+eefz8CBA/OLX/xihd7TJAYAAAAAaOGWLl2aM888MwsWLFjhdy2uAwAAAADI6k31rm1XX311OnXqtFLvShIDAAAAALRgEydOzG233ZbLLrtspd6XJAYAAAAASFJNQyGfO3To0A98PmHChPd9Nm/evJx99tn52te+lo022milPl+SGAAAAACghbrwwgszcODAHHjggSt9hyQxAAAAAECBPigp/EHGjRuXRx99NHfeeecqfb4mMQAAAABAkkox0yZW2h133JE5c+Zkzz33bHY+YsSI/OY3v8mPfvSjmu7RJAYAAAAAaIFGjx6dRYsWNTsbNmxYTjnllHzqU5+q+R5NYgAAAACAJJWCFtetrO7du7/n+frrr/++z96LxXUAAAAAACUmSQwAAAAAUCemTJmywu9oEgMAAAAAJKkWXUBBjJsAAAAAACgxSWIAAAAAgCSVogsoiCQxAAAAAECJaRIDAAAAAJSYcRMAAAAAAEkqDQ1Fl1AISWIAAAAAgBKTJAYAAAAASFItuoCCSBIDAAAAAJSYJDEAAAAAQJJK0QUURJIYAAAAAKDENIkBAAAAAErMuAkAAAAAgCSVhqIrKIYkMQAAAABAiUkSAwAAAAAkqaScUWJJYgAAAACAEtMkBgAAAAAoMeMmAAAAAACSVIsuoCCSxAAAAAAAJSZJDAAAAACQpFLOvXWSxAAAAAAAZSZJDAAAAACQpFJ0AQWRJAYAAAAAKDFNYgAAAACAEjNuAgAAAAAgSbXoAgoiSQwAAAAAUGKSxAAAAAAASSoNRVdQDEliAAAAAIAS0yQGAAAAACgx4yagJWjbmK63/jYNbZr/I1tduCCvf/6T7/rtHT5/VDocfvT7Xjfv/FPS9Pe/rPYyAah/d/xhUm4aPzEvz5mbjdbrksP23jGH7blDGhpK+nN5AKwxDY1t0/PPv0pD2+bfB1UWLMw/dvl0QVUB9a5SdAEF0SSGFqD1Zr3S0KZN5o8ZmWWvvPw/Dyrv/T9di+69K0sef6TZWUObNul01oWpvD4nTVOfWpPlAlCnfvHApIz86W9z+N47Zs/t++XxqS/kW7fckyVLm3LksF2KLg+AOtO2b880tG2TWedelqUv/K/vg5aVtYUDsOZoEkML0KZX31SbmrLkwfuTpqX/8vdX57yaZXNebXb2kS99JQ0dOmT+OV9PlixZU6UCUMfGPfjXDOy7Sc45fFiSZJcte2b6jDm59f88pkkMwGrXrn+fVJc2Zf49DyRL//X3QQCrQ1n/GMpMYmgBWvfqm2Uv/rOmBvF7vr9Z77Q74OAsvHVsKrNmrObqACiLJUub0rFDu2Zn63TqkLlvLSyoIgDqWWP/Pln6jxc0iAHWAkliaAFa9+qbVJal84Wj02bLbVJdujRLHrwvC8Z+P1n4r78x73DUCanMnJFFv759LVQLQL36j6GD8s3/+k3u+vOTGTKgb/723Mu5809P5oDB2xRdGgB1qN0WfVJtWpYe141K++23TnXpkrx1zwOZM/r6VBf4A0pgzaiWdNVGzU3if/zjH7nzzjszd+7cDBkyJEOGDGn2fP78+bnkkksyatSo1V4klF2bnn2ShoYsuPf/y8Kf/XfabN4/HT5/VFr/W8+8ecEpSbX6vu+23qx3GnfYJW997/KksmwtVg1Avfnkzlvn0Sn/zAU33Ln87N+37pWzDtunwKoAqFeN/XolDQ158xe/zRvX35x2W/dL1xOPSNvem+aVo8/8wO+DAFgxNTWJH3vssRxzzDHp1q1bGhoactNNN2XYsGG54oor0tjYmCRZtGhRxo0bp0kMq1tDQ9685PxU576RZS/8I0nSNPmvqbzxWjqd/vW0Hbhzlj7+8Pu+3m7/g1N547Us/v3da6lgAOrVV6+5PU9MfTFfPWSvbNPzo3n2pVm59s4/5qzrfplvn/TZNDSUNHYBwOrX0JAZJ4/IstfnZum06UmSRY/9LcvmvJ5ul52bDrsNysI/Tiy4SID6UdNM4iuvvDKf/exnc8899+Tuu+/Od77znfzxj3/MSSedlKampjVdI5RbtZqmJyctbxC/Y+mjf06StO7V5/3fbdUqjbt+LEsevC/xzyoAq2DSsy/mwSefy5mHDc1RH981g7bYNJ/fe1BGfumA3Ddpah7467NFlwhAPalWs+jRvy5vEL9jwR/eDsg0btG7iKqAEqgU9FW0mprEU6ZMyZFHHrn81x//+Mfzwx/+MI899ljOOeecNVYckDSst37a7XtAWm3QrfmD/z/FX5n7xvu+26bflmm1zrpZ8sffr8EKASiDV+bMTZJs33eTZuc7br5pkmTay7PXek0A1K/WG66Xzp/9ZFr32LDZeUO7txeoVl6bW0RZAHWrpiZxp06dMmfOnGZnO+ywQ6644or89re/NWIC1qCGVq3T8T/PSrtPfKrZeePue6e6rClNk//6vu+26bd1qk1NaZr69JouE4A612uj9ZMkj099odn5pGdfTJJsvOG6a7skAOpZ69bZ8MLT0uXQ/Zsdd/zEHqk2Lcuix/9WUGFAvStrkrimmcR77LFHvvnNb+ab3/xmtt5667Rt2zZJss8+++T888/PxRdfnFdeeWWNFgplVZk9K4vH/ybtP/P5VBcvTtOUv6fNltumw6FHZPFdv0zl5RfT0GWdtOqx8dsjKRYuWP5u6569U5n5crJ0SXH/BQCoC/037ZF9dtgiV/5sQt58a1G26f3RTHt5dq779QPZarMe2XvgFkWXCEAdWTbj1bz5y99l3aMPTXXxkiz6y+S0H7hNuh73+cy75VdZOv2loksEqCs1NYnPOOOMnHbaaTn88MNz3XXXZciQIcufHXHEEWnVqlUuvfTSNVYklN1bPxiTZTNeTru9hqXD576QypxXs/DmH2fRL29NkrQdNDidTj0v8y44NU1PTlr+XsM6XVOd/2ZBVQNQb0Yd9+n88K4H8/P7n8j3f/1AeqzXJZ/abUCOP2D3tGld0w+oAUDNXh15dZa+OCOdDhiadb/8H1k289W8ds1/Z+5Pfl50aQB1p6FarVZr/c3//Oc/07Vr13Tu3Pldz55//vncc889Of7441e5qNc+vccq3wEAtepwxtFFlwBASbzylZuLLgGAkuj9t3uKLqFFuvrfjijkc09+4cZCPvcdNSWJ37Hpppu+77NevXqtlgYxAAAAAABrzwo1iQEAAAAA6lWloegKimF4HAAAAABAiUkSAwAAAAAkqRRdQEEkiQEAAAAASkyTGAAAAACgxIybAAAAAACIcRMAAAAAAJSQJDEAAAAAQJJq0QUURJIYAAAAAKDENIkBAAAAAErMuAkAAAAAgCSVhqIrKIYkMQAAAABAiUkSAwAAAAAkqRRdQEEkiQEAAAAASkyTGAAAAAAgSbWgr1UxZ86cnHXWWdl1110zcODAfPnLX860adNW6A5NYgAAAACAFuorX/lKpk+fnuuvvz6333572rdvn6OOOioLFy6s+Q5NYgAAAACAFmju3LnZeOONc/HFF2fAgAHp06dPTjrppMyaNStTp06t+R6L6wAAAAAAklRWefjDyhk6dOgHPp8wYcJ7nq+zzjq58sorl//6tddey9ixY9OjR4/07du35s/XJAYAAAAAaOG+/vWv52c/+1kaGxvzgx/8IB/5yEdqfleTGAAAAAAgSaWgz32/pPCK+OIXv5jDDjssN910U77yla/k5ptvztZbb13Tu2YSAwAAAAC0cH379s0222yTSy65JBtvvHFuvPHGmt/VJAYAAAAAaIFee+213HXXXWlqalp+1qpVq/Tt2zezZs2q+R5NYgAAAACAJNWCvlbW7Nmzc/rpp+ehhx5afrZ06dJMnjw5ffr0qfkeTWIAAAAAgBaoX79+GTJkSC6++OJMnDgxzzzzTM4999zMmzcvRx11VM33aBIDAAAAAOTtxXVFfK2KMWPGZPDgwTnttNNy6KGH5o033shNN92Uj370ozXf0WYVawAAAAAAoCCdO3fOhRdemAsvvHCl79AkBgAAAABIUmkouoJiGDcBAAAAAFBimsQAAAAAACVm3AQAAAAAQJJKqkWXUAhJYgAAAACAEpMkBgAAAABISpojliQGAAAAACg1TWIAAAAAgBIzbgIAAAAAIEml6AIKIkkMAAAAAFBiksQAAAAAAEkqJV1dJ0kMAAAAAFBimsQAAAAAACVm3AQAAAAAQFLSYROSxAAAAAAApSZJDAAAAACQpFJ0AQWRJAYAAAAAKDFJYgAAAACAJJWSTiWWJAYAAAAAKDFNYgAAAACAEjNuAgAAAAAgKemwCUliAAAAAIBSkyQGAAAAAEhSKbqAgkgSAwAAAACUmCYxAAAAAECJGTcBAAAAAJCkWtLVdZLEAAAAAAAlJkkMAAAAABCL6wAAAAAAKCFJYgAAAACAJBUziQEAAAAAKBtNYgAAAACAEjNuAgAAAAAgKemwCUliAAAAAIBSkyQGAAAAAIjFdQAAAAAAlJAmMQAAAABAiRk3AQAAAACQpFJ0AQWRJAYAAAAAKDFJYgAAAACAJFWL6wAAAAAAKBtJYgAAAACAmEkMAAAAAEAJaRIDAAAAAJTYh3LcROcbflJ0CQCUSNPkPxRdAgAl0eOEfkWXAAB8AIvrAAAAAAAonQ9lkhgAAAAAYG2zuA4AAAAAgNLRJAYAAAAAKDHjJgAAAAAAklSqFtcBAAAAAFAyksQAAAAAAEnKmSOWJAYAAAAAKDVJYgAAAACAJJWSZokliQEAAAAASkyTGAAAAACgxIybAAAAAABIUm2B4ybeeOONjBkzJvfdd1/mz5+fLbbYImeccUYGDRpU8x2SxAAAAAAALdTpp5+eJ554ImPGjMkdd9yRLbfcMsccc0yee+65mu/QJAYAAAAASFIp6GtlTZ8+PQ8++GAuvPDCDBo0KL169crXv/71dOvWLXfeeWfN92gSAwAAAAC0QF27ds3111+fbbfddvlZQ0NDGhoaMm/evJrvMZMYAAAAAKBAQ4cO/cDnEyZMeM/zLl26ZI899mh2dvfdd2f69Ok5//zza/58TWIAAAAAgCSVFri47n97/PHHc95552XYsGHZc889a35PkxgAAAAAoEDvlxReEePHj8+ZZ56ZHXbYIaNHj16hd80kBgAAAABIUi3or1V144035uSTT85ee+2Va6+9Nu3atVuh9zWJAQAAAABaqJtvvjkjR47M8OHDM2bMmDQ2Nq7wHcZNAAAAAAAkqRRdwAp6/vnnc+mll2bffffN8ccfn9mzZy9/1r59+3Tu3LmmezSJAQAAAABaoLvvvjtLly7Nvffem3vvvbfZs4MOOiiXXXZZTfdoEgMAAAAAtEAnnHBCTjjhhFW+R5MYAAAAACBJtbrqS+RaIovrAAAAAABKTJIYAAAAACBJJZLEAAAAAACUjCYxAAAAAECJGTcBAAAAAJCkUnQBBZEkBgAAAAAoMUliAAAAAIAkVYvrAAAAAAAoG0liAAAAAIAkFUliAAAAAADKRpMYAAAAAKDEjJsAAAAAAEhSrRo3AQAAAABAyUgSAwAAAAAkqRRdQEEkiQEAAAAASkyTGAAAAACgxIybAAAAAABIUo3FdQAAAAAAlIwkMQAAAABAkookMQAAAAAAZaNJDAAAAABQYsZNAAAAAAAkqVaNmwAAAAAAoGQkiQEAAAAAYnEdAAAAAAAlJEkMAAAAAJCkKkkMAAAAAEDZaBIDAAAAAJSYcRMAAAAAAEkqVeMmAAAAAAAoGUliAAAAAICkpGvrJIkBAAAAAEpNkxgAAAAAoMSMmwAAAAAASFIp6cAJSWIAAAAAgBKTJAYAAAAAiCQxAAAAAAAlJEkMAAAAAJCkWpUkBgAAAACgZDSJAQAAAABKzLgJAAAAAIBYXAcAAAAAQAlJEgMAAAAAJKlKEgMAAAAAUDaaxAAAAAAAJWbcBLRwlUol/3XrL/Kzcb/JzFdnZ+ONeuTwgw/IfxzyqaJLA6AO3fGHSblp/MS8PGduNlqvSw7be8cctucOaWhoKLo0AOrIoy++luN+8dj7Pj9hl945fpc+a7EioCyq1XKOm9Akhhbuiqt/mJ/+bFw+95n9MnTIv+eFl1/J937407z0ysycdfJxRZcHQB35xQOTMvKnv83he++YPbfvl8envpBv3XJPlixtypHDdim6PADqSP8Nu+S/Dt3pXefX/HlaJs+cl0/061FAVQD1S5MYWrDX35ibm+/4dT574CfyjbNOXn7eo9uGOeXci/LZT30ivTf7twIrBKCejHvwrxnYd5Occ/iwJMkuW/bM9Blzcuv/eUyTGIDVqlO7Nhmw0brNzu57blYeeeG1XP7JAdmsa8diCgPqXsXiOqCl+ccLL2XZskr23K35N+Y777BdKpVKHvzzowVVBkA9WrK0KR07tGt2tk6nDpn71sKCKgKgLBY1Lcu37p+Sj/XcIPtu3r3ocgDqjiYxtGBd1+mSJHl5xsxm5y+89Mrbf395xlqvCYD69R9DB+Whvz+Xu/78ZN5csCh/evK53PmnJ7P/rtsUXRoAde7mSf/Mq/MX58whWxRdClDnqtVqIV9FW6FxE4sXL87UqVPTt2/ftG/fPk899VRuvPHGzJw5M5tvvnm++MUvpkcPc4Fgbem56SbZYcDWueaGG9O92wbZZcft8+LLr+TCb12Vxsa2WbhoUdElAlBHPrnz1nl0yj9zwQ13Lj/796175azD9imwKgDq3dJlldwy6Z/5eL/u2XTdjxRdDkBdqjlJ/Nxzz2XffffNIYcckv322y9/+tOfcvjhh2fSpEnp2LFjxo8fn09/+tOZNm3amqwX+H+MueSCDNp+23z1/Isz+OOH5JhTzsuhn/5k1u3SJR3atfvXFwBAjb56ze0Z/9iUfPWQvfKjM4fn3MP3zeTpM3LWdb/8UKQfAKhP45+dmdkLluTIHXoWXQpA3ao5Sfytb30r22+/fU466aSMHTs2J554Yvbff/9ccsklaWhoSFNTU84555yMGjUqP/rRj9ZkzcD/ssF6XXPVZd/IvDfn59XZc/JvG2+UVq1a56IrvpcuXToXXR4AdWLSsy/mwSefyzeO/GQO/tj2SZJBW2yajTdcNydf9fM88NdnM2S7zYstEoC6NP7ZWemzXsdssaHvb4A1z+K6f+GRRx7JV7/61fTv3z9nn312Fi9enCOOOCINDQ1JkjZt2uT444/PY489tsaKBd7tN+Pvy5Rnn0+Xzp3Sp9dmaWxszNNTp6VSqWSrLfoWXR4AdeKVOXOTJNv33aTZ+Y6bb5okmfby7LVeEwD1b+mySv40fbZldQBrWM1N4vbt22fhwrc3V6+33nr53Oc+l3b/z4+yz5s3L507+5M9WJuuH3trfvTT25qd/fS2X6Zzp47ZaeCAgqoCoN702mj9JMnjU19odj7p2ReTJBtvuO7aLgmAEnh2zvwsaqpk+4+uW3QpQElUC/qraDWPm9h9990zcuTIXHzxxenbt28uuuii5c8qlUoeeuihjBw5MvvsY3EJrE3DD/1ULrrie+nbe7MM3Gar/HbC/bnr3vvy9TP/M507dSy6PADqRP9Ne2SfHbbIlT+bkDffWpRten80016enet+/UC22qxH9h5o2zwAq9/UOfOTJL3X61RwJQD1reYk8XnnnZckufbaa9/17He/+12OOeaYbLbZZjn99NNXX3XAv3Top/fL2ad8OePuujdfOXtEnnzqmVx+4Tk57KD9iy4NgDoz6rhP5wv77pyf3/9ETvrObblp/MR8arcB+dGZw9Omdc3/WgkANXttwZIkSZd2NWfcAErtuuuuyxe+8IUVfq+huoKrqOfNm5cuXbo0O3v99dcze/bsbL756llWsnT2c6vlHgCoRdPkPxRdAgAlUf3bo0WXAEBJfOQr3yu6hBZpm+67FvK5T8788yrfcdNNN+Xiiy/OoEGD8tOf/nSF3l3hP4r7fxvESdK1a9d07dp1Ra8CAAAAAGAVzJw5MyNGjMjDDz+cnj17rtQdfl4DAAAAACApbInc0KFDP/D5hAkT3vfZ3//+97Rt2za//vWvc8011+Sll15a4c/XJAYAAAAAaKH23nvv7L333qt0hyYxAAAAAECSyoqtb1ttPigpvDZYQw0AAAAAUGKaxAAAAAAAJWbcBAAAAABAiltcVzRJYgAAAACAEpMkBgAAAABIcYvriqZJDAAAAABQBy677LKVes+4CQAAAACAEpMkBgAAAACIxXUAAAAAAJSQJDEAAAAAQMq7uE6SGAAAAACgxCSJAQAAAABiJjEAAAAAACWkSQwAAAAAUGLGTQAAAAAAJKlWK0WXUAhJYgAAAACAEpMkBgAAAABIUrG4DgAAAACAstEkBgAAAAAoMeMmAAAAAACSVKvGTQAAAAAAUDKSxAAAAAAAsbgOAAAAAIASkiQGAAAAAIiZxAAAAAAAlJAmMQAAAABAiRk3AQAAAACQpGLcBAAAAAAAZSNJDAAAAACQpBpJYgAAAAAASkaTGAAAAACgxIybAAAAAABIUrW4DgAAAACAspEkBgAAAABIUrG4DgAAAACAstEkBgAAAAAoMeMmAAAAAABicR0AAAAAACUkSQwAAAAAkKQiSQwAAAAAQNlIEgMAAAAAxExiAAAAAABKSJMYAAAAAKDEjJsAAAAAAEhSiXETAAAAAACUjCQxAAAAAEAsrgMAAAAAoIQ0iQEAAAAASsy4CQAAAACAJBXjJgAAAAAAKBtJYgAAAACAJNVIEgMAAAAAUDKSxAAAAAAAMZMYAAAAAIAS0iQGAAAAACgx4yYAAAAAAJJUjZsAAAAAAKBsJIkBAAAAAJJUI0kMAAAAAEDJaBIDAAAAAJSYcRMAAAAAALG4DgAAAACAEtIkBgAAAADI20niIr5WRaVSyVVXXZWPfexj2X777XPcccflhRdeWKE7NIkBAAAAAFqo73//+7n55pszcuTI3HrrralUKjn22GOzZMmSmu/QJAYAAAAASFIt6GtlLVmyJD/+8Y9zyimnZM8990z//v3z7W9/OzNmzMg999xT8z2axAAAAAAALdDTTz+dt956K4MHD15+1qVLl2y11VaZOHFizfe0WRPFAQAAAABQm6FDh37g8wkTJrzn+YwZM5IkG220UbPzbt26LX9Wiw9lk7jtBr2LLgGAEmk7xP/vALCWDDmq6AoAgA/QtOSlQj73XzWJ38/ChQuTJI2Njc3O27Vrl7lz59Z8z4eySQwAAAAAUBbvlxT+V9q3b5/k7dnE7/znJFm8eHE6dOhQ8z1mEgMAAAAAtEDvjJmYNWtWs/NZs2ale/fuNd+jSQwAAAAA0AL1798/nTp1ysMPP7z8bN68eZk8eXJ22mmnmu8xbgIAAAAAoAVqbGzMEUcckdGjR2e99dbLxhtvnCuuuCI9evTIsGHDar5HkxgAAAAAoIU65ZRT0tTUlK997WtZtGhRdtppp9xwww1p27ZtzXc0VKvV6hqsEQAAAACADzEziQEAAAAASkyTGAAAAACgxDSJAQAAAABKTJMYAAAAAKDENIkBAAAAAEpMkxgAAAAAoMQ0iQEAAAAASkyTGFq4SqWSq666Kh/72Mey/fbb57jjjssLL7xQdFkAlMB1112XL3zhC0WXAUCdeuONN/KNb3wjQ4YMyQ477JDDDz88jz76aNFlAdQlTWJo4b7//e/n5ptvzsiRI3PrrbemUqnk2GOPzZIlS4ouDYA6dtNNN+U73/lO0WUAUMdOP/30PPHEExkzZkzuuOOObLnlljnmmGPy3HPPFV0aQN3RJIYWbMmSJfnxj3+cU045JXvuuWf69++fb3/725kxY0buueeeossDoA7NnDkzJ5xwQkaPHp2ePXsWXQ4AdWr69Ol58MEHc+GFF2bQoEHp1atXvv71r6dbt2658847iy4PoO5oEkML9vTTT+ett97K4MGDl5916dIlW221VSZOnFhgZQDUq7///e9p27Ztfv3rX2e77bYruhwA6lTXrl1z/fXXZ9ttt11+1tDQkIaGhsybN6/AygDqU5uiCwBW3owZM5IkG220UbPzbt26LX8GAKvT3nvvnb333rvoMgCoc126dMkee+zR7Ozuu+/O9OnTc/755xdUFUD9kiSGFmzhwoVJksbGxmbn7dq1y+LFi4soCQAAYLV7/PHHc95552XYsGHZc889iy4HoO5oEkML1r59+yR515K6xYsXp0OHDkWUBAAAsFqNHz8+X/rSl7L99ttn9OjRRZcDUJc0iaEFe2fMxKxZs5qdz5o1K927dy+iJAAAgNXmxhtvzMknn5y99tor1157bdq1a1d0SQB1SZMYWrD+/funU6dOefjhh5efzZs3L5MnT85OO+1UYGUAAACr5uabb87IkSMzfPjwjBkz5l1j9gBYfSyugxassbExRxxxREaPHp311lsvG2+8ca644or06NEjw4YNK7o8AACAlfL888/n0ksvzb777pvjjz8+s2fPXv6sffv26dy5c4HVAdQfTWJo4U455ZQ0NTXla1/7WhYtWpSddtopN9xwQ9q2bVt0aQAAACvl7rvvztKlS3Pvvffm3nvvbfbsoIMOymWXXVZQZQD1qaFarVaLLgIAAAAAgGKYSQwAAAAAUGKaxAAAAAAAJaZJDAAAAABQYprEAAAAAAAlpkkMAAAAAFBimsQAAAAAACWmSQwAAAAAUGKaxAAAAAAAJaZJDAAAAABQYprEAAAAAAAlpkkMAAAAAFBi/xfYJUbpwwwodAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simp_imp = SimpleImputer()\n",
    "sns.heatmap(simp_imp.fit_transform(X), annot=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea39297c2a3b8433e0e3c4b620aff79df88eb4bda961dfb2311fbafd7efdbd77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
