{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "try:\n",
    "  import keras_tuner as kt\n",
    "except:\n",
    "  !pip install keras-tuner\n",
    "  import keras_tuner as kt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input, BatchNormalization, Normalization\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "import sklearn\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "# Helper to plot loss\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "def plot_acc(history):\n",
    "  plt.plot(history.history['accuracy'], label='accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Settings\n",
    "BASE_EPOCHS = 5\n",
    "BATCH_SIZE = 1024\n",
    "BASE_PATIENCE = 5\n",
    "MIN_DELTA = .02\n",
    "MONITOR = \"val_loss\"\n",
    "CRITERIA = \"min\"\n",
    "LOGS = \"logs\"\n",
    "DIR_OUT = \"kt_out\"\n",
    "PROJECT = \"kt_basics\"\n",
    "FACTOR = 3\n",
    "VALIDATION = .2\n",
    "MAX_TRIALS = 3\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  BASE_EPOCHS = 6\n",
    "  BATCH_SIZE = 1024\n",
    "  BASE_PATIENCE = 3\n",
    "  MAX_TRIALS = 10\n",
    "  !pip install keras_tuner\n",
    "\n",
    "# Metrics\n",
    "acc = keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "pre = keras.metrics.Precision(name=\"precision\")\n",
    "rec = keras.metrics.Recall(name=\"recall\")\n",
    "metric_list = [acc, pre, rec]\n",
    "\n",
    "HPARAM = True\n",
    "\n",
    "stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=MONITOR,\n",
    "    min_delta=MIN_DELTA,\n",
    "    patience=BASE_PATIENCE,\n",
    "    mode=CRITERIA,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner\n",
    "\n",
    "We can use the Keras Tuner to find the best hyperparameters for our model, in a similar way to how we usd a grid search to find the best hyperparameters for our scikit-learn models. The process is a little more involved, but it's still pretty straightforward. \n",
    "\n",
    "### Logs and Records\n",
    "\n",
    "All of the stuff we are looking at here relies on log and record files being saved to disk. We can save them anywhere, but it is probably a good idea to consolidate them in some organized way. We can do this by creating a new directory called `logs` in the root of our project, and putting the log results in there. One thing to watch out for is that you can sometimes get odd errors or warnings if you are looking at the log files for some other model. This is because it is expecting to find things that it has written for the model to which it belongs. This is very annoying, ask me how I know. For real applications, youd probably want to make specific folders to track these things - for our repeated trials, I have added a little datetime stamp to some file names to just ensure that they are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "\n",
    "We will start with using the cifar dataset. \n",
    "\n",
    "This is loaded up above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Note: the class names are taken from the documentation\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image_grid(dataset=X_train, indices=None):\n",
    "    \"\"\"\n",
    "    Displays a grid of 4 images from the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The dataset to display images from. Defaults to X_train.\n",
    "    - indices: A list of up to 4 integers specifying which images to include. \n",
    "               If None or fewer than 4 entries, selects randomly.\n",
    "    \"\"\"\n",
    "    if indices is None or len(indices) < 4:\n",
    "        indices = indices or []\n",
    "        indices += random.sample(range(len(dataset)), 4 - len(indices))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(4, 4))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(dataset[indices[i]])\n",
    "        ax.axis('off')\n",
    "        #ax.set_title(f'Label: {class_names[np.argmax(y_train[indices[i]])]} \\nIndex: {indices[i]}')\n",
    "        ax.set_title(str(indices[i])+\": \"+class_names[np.argmax(y_train[indices[i]])])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Builder\n",
    "\n",
    "To use Keras Tuner, you need to define a model builder function. This function takes a hyperparameter dictionary as input and returns a compiled model. In plain language, the model builder function is basically a framework for creating a model, with the key difference that we set things up so that the hyperparameters that we are testing are variables in the model construction. \n",
    "\n",
    "### HP.whatever\n",
    "\n",
    "The hyperparameters that we are testing are defined using the HP.[Type_of_choice] functions. For example, HP.Choice defines a hyperparameter that can take on one of a list of values. HP.Float defines a hyperparameter that can take on any value between a minimum and maximum value. HP.Int defines a hyperparameter that can take on any integer value between a minimum and maximum value. Each thing that we want to change in the search is set up with one of these \"hp.\" functions, along with the range of values we want to test.\n",
    "\n",
    "When the hyperparameter search is called, these hyperparameters will be varied according to the search algorithm that we choose - just as a grid search would work through the various combinations of hyperparameters in the list we supply. We can build this model builder function to test almost anything we can think of - different number of neurons, different number of layers, different types of layers, different activation functions, different optimizers, different learning rates, etc... The possibilities of what we can test are really only limited by our imagination and the time it takes to run the search. Some key hp items to be aware of are:\n",
    "<ul>\n",
    "<li>HP.Choice - a hyperparameter that can take on one of a list of values</li>\n",
    "<li>HP.Float - a hyperparameter that can take on any value between a minimum and maximum value</li>\n",
    "<li>HP.Int - a hyperparameter that can take on any integer value between a minimum and maximum value</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(32, 32, 3)))\n",
    "\n",
    "    for i in range(hp.Int(\"conv_layers\", 1, 3)):\n",
    "        model.add(Conv2D(hp.Int(f\"filters_{i}\", 32, 256, step=32), 3, activation=\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for i in range(hp.Int(\"dense_layers\", 1, 2)):\n",
    "        model.add(Dense(hp.Int(f\"dense_units_{i}\", 32, 256, step=32), activation=\"relu\"))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", [.01, .001, .0001])),\n",
    "                    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning\n",
    "\n",
    "Our model builder is the core of the hyperparameter tuning process, using it is relatively simple. We use the model builder as an input to the type of parameter search we want to do, there are a few options offered in the keras tuner:\n",
    "<ul>\n",
    "<li> Grid search - searches over a grid of hyperparameters like we are used to. </li>\n",
    "<li> Random search - randomly selects hyperparameters from the search space and trains a model for each combination. </li>\n",
    "<li> Hyperband - a more advanced search algorithm that uses early stopping to quickly identify high-performing models. This is a good option when you have a large search space and want to run a quick search. (The factor represents a ratio that the algorithm reduces the number of models trained from trial to trial, lower values leave more models)</li>\n",
    "<li> Bayesian optimization - uses Bayesian optimization to identify high-performing hyperparameter values. Specifically, it starts by randomly selecting things, then uses performance to be smart about which others to select. </li>\n",
    "</ul>\n",
    "\n",
    "Once we've setup the search, we call the search() function in a very similar way to the fit() function. The search() function will run the search and find the best set of hyperparameters for our model. The Baeysian or Hyperband will likely perform much more quickly, especially as the seach space expands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(hypermodel = model_builder,\n",
    "                     objective=MONITOR,\n",
    "                     max_epochs=BASE_EPOCHS,\n",
    "                     factor=3,\n",
    "                     directory=DIR_OUT,\n",
    "                     project_name=PROJECT,\n",
    "                     overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First - Simple Model for Tensorboard\n",
    "\n",
    "We'll generate some results so our tensorboard isn't naked when we pull it up, it's kind of bashful. This model is mostly so we have an example of 'many epochs' to see in the training results. The hyperparameter search tends to have lots of low epoch trials and we set the epochs relatively low because it is a slow process to begin with, so this will give us a real curve to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">921,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m921,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">923,914</span> (3.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m923,914\u001b[0m (3.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">923,914</span> (3.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m923,914\u001b[0m (3.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2062 - loss: 2.3227 - val_accuracy: 0.3541 - val_loss: 1.8232\n",
      "Epoch 2/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.3798 - loss: 1.7546 - val_accuracy: 0.4271 - val_loss: 1.6444\n",
      "Epoch 3/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4467 - loss: 1.5954 - val_accuracy: 0.4640 - val_loss: 1.5398\n",
      "Epoch 4/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4775 - loss: 1.5008 - val_accuracy: 0.4764 - val_loss: 1.4808\n",
      "Epoch 5/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5017 - loss: 1.4259 - val_accuracy: 0.5141 - val_loss: 1.4063\n",
      "Epoch 6/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.5168 - loss: 1.3730 - val_accuracy: 0.5200 - val_loss: 1.3841\n",
      "Epoch 7/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5417 - loss: 1.3151 - val_accuracy: 0.5272 - val_loss: 1.3540\n",
      "Epoch 8/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5579 - loss: 1.2786 - val_accuracy: 0.5378 - val_loss: 1.3179\n",
      "Epoch 9/30\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.5617 - loss: 1.2592"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[134]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m modelMini.compile(optimizer=\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, loss=keras.losses.CategoricalCrossentropy(from_logits=\u001b[38;5;28;01mTrue\u001b[39;00m), metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     11\u001b[39m modelMini.summary()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m historyMini = \u001b[43mmodelMini\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVALIDATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_callback0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m plot_loss(historyMini)\n\u001b[32m     19\u001b[39m plot_acc(historyMini)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tensorboard_callback0 = keras.callbacks.TensorBoard(log_dir=LOGS+\"/basic\", write_graph=False, write_images=False)\n",
    "\n",
    "modelMini = Sequential()\n",
    "modelMini.add(Input(shape=(32, 32, 3)))\n",
    "modelMini.add(Conv2D(32, 3, activation=\"relu\"))\n",
    "modelMini.add(MaxPooling2D())\n",
    "modelMini.add(Flatten())\n",
    "modelMini.add(Dense(128, activation=\"relu\"))\n",
    "modelMini.add(Dense(10))\n",
    "modelMini.compile(optimizer=\"adam\", loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "modelMini.summary()\n",
    "\n",
    "callbacksMini = [stopping]\n",
    "if HPARAM:\n",
    "  callbacksMini.append(tensorboard_callback0)\n",
    "\n",
    "historyMini = modelMini.fit(X_train, y_train, epochs=30, \n",
    "                            validation_split=VALIDATION, \n",
    "                            callbacks=callbacksMini,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            verbose=1)\n",
    "plot_loss(historyMini)\n",
    "plot_acc(historyMini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 7746), started 7:54:58 ago. (Use '!kill 7746' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a7fc4c426095e223\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a7fc4c426095e223\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Results\n",
    "\n",
    "We can get the results of the trial, just like in a grid seach. One note on getting the best models or parameters down below is that we can get more than one. Below we are only grabbing the best model and hyperparameters, but we could get the top 3 or however many we wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 23s]\n",
      "val_loss: 2.0288808345794678\n",
      "\n",
      "Best val_loss So Far: 2.0288808345794678\n",
      "Total elapsed time: 00h 01m 10s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |1                 |conv_layers\n",
      "128               |160               |filters_0\n",
      "0.1               |0.1               |dropout_0\n",
      "2                 |1                 |dense_layers\n",
      "96                |224               |dense_units_0\n",
      "0.0001            |0.01              |learning_rate\n",
      "224               |32                |filters_1\n",
      "0.1               |0                 |dropout_1\n",
      "32                |192               |filters_2\n",
      "0.4               |0.3               |dropout_2\n",
      "224               |128               |dense_units_1\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.1291 - loss: 2.2913"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m HPARAM:\n\u001b[32m      5\u001b[39m   callbacks1.append(tensorboard_callback1)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBASE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVALIDATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[32m      9\u001b[39m best_hps = tuner.get_best_hyperparameters(num_trials=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[39m, in \u001b[36mHyperband.run_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    425\u001b[39m     fit_kwargs[\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m] = hp.values[\u001b[33m\"\u001b[39m\u001b[33mtuner/epochs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    426\u001b[39m     fit_kwargs[\u001b[33m\"\u001b[39m\u001b[33minitial_epoch\u001b[39m\u001b[33m\"\u001b[39m] = hp.values[\u001b[33m\"\u001b[39m\u001b[33mtuner/initial_epoch\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_mar_2025/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Get Results\n",
    "tensorboard_callback1 = keras.callbacks.TensorBoard(log_dir=LOGS+\"/hparam1\", write_graph=False, write_images=True)\n",
    "callbacks1 = [stopping]\n",
    "if HPARAM:\n",
    "  callbacks1.append(tensorboard_callback1)\n",
    "tuner.search(X_train, y_train, epochs=BASE_EPOCHS, validation_split=VALIDATION, callbacks=callbacks1, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of conv layers is {best_hps.get('conv_layers')}, \n",
    "the optimal number of dense layers is {best_hps.get('dense_layers')}, \n",
    "the optimal number of filters is {best_hps.get('filters_0')}, \n",
    "the optimal number of dense units is {best_hps.get('dense_units_0')}, \n",
    "and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')},\n",
    "The performance of the best model is:\n",
    "{best_model.evaluate(X_test, y_test)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Best Model\n",
    "\n",
    "Once we have the best parameters, we can train a final model. Here I'll train a model on ALL of the data, since we already know the best parameter, this is the model that we think will do the best job and will be the one we can use in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - categorical_accuracy: 0.1983 - loss: 2.1702 - val_categorical_accuracy: 0.3659 - val_loss: 1.7513\n",
      "Epoch 2/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 297ms/step - categorical_accuracy: 0.3658 - loss: 1.7498 - val_categorical_accuracy: 0.4361 - val_loss: 1.5674\n",
      "Epoch 3/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 310ms/step - categorical_accuracy: 0.4391 - loss: 1.5586 - val_categorical_accuracy: 0.4723 - val_loss: 1.4748\n",
      "Epoch 4/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 309ms/step - categorical_accuracy: 0.4763 - loss: 1.4757 - val_categorical_accuracy: 0.5031 - val_loss: 1.3955\n",
      "Epoch 5/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 300ms/step - categorical_accuracy: 0.4976 - loss: 1.4137 - val_categorical_accuracy: 0.5131 - val_loss: 1.3439\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m   callbacks2.append(tensorboard_callback1)\n\u001b[32m      7\u001b[39m history = model.fit(X_train, y_train, epochs=BASE_EPOCHS, validation_split=VALIDATION, callbacks=callbacks2, batch_size=BATCH_SIZE)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m val_acc_per_epoch = \u001b[43mhistory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m best_epoch = val_acc_per_epoch.index(\u001b[38;5;28mmax\u001b[39m(val_acc_per_epoch)) + \u001b[32m1\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mBest epoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m % (best_epoch,))\n",
      "\u001b[31mKeyError\u001b[39m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "tensorboard_callback2 = keras.callbacks.TensorBoard(log_dir=LOGS+\"/full_train1\", write_graph=False, write_images=True)\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "callbacks2 = [stopping]\n",
    "if HPARAM:\n",
    "  callbacks2.append(tensorboard_callback2)\n",
    "history = model.fit(X_train, y_train, epochs=BASE_EPOCHS, validation_split=VALIDATION, callbacks=callbacks2, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints \n",
    "\n",
    "We can also use checkpoints to save the best model as we go, this is a good way to make sure we don't lose our best model if we have to stop the training process early. This is also a good way to make sure we don't have to retrain the model if we have to restart the notebook.\n",
    "\n",
    "#### Checkpoint Callback\n",
    "\n",
    "We can build the checkpoint saving process into our model training fairly easily, by putting it into a callback. This callback is a lot like the early stopping one, but instead it just saves the weights of the model whenever it sees an improvement. If the next epoch is better, we save the updated model, if it is worse, we do nothing. On subsequent runs, we can load the weights from the checkpoint and continue training if we wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filepath=\"logs/weights/weights-improvement-\"+file_time+\".keras\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor=MONITOR, verbose=1, save_best_only=True, mode=CRITERIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Weights\n",
    "\n",
    "Only the weights are saved in the checkpoint, it is assumed we already have the model's structure. To pick up from our checkpoint, we need to:\n",
    "<ul>\n",
    "<li> Create a model that is the correct structure. </li>\n",
    "<li> Retreive the weights from the checkpoint file. </li>\n",
    "<li> Load the weights into the model. </li>\n",
    "<li> Compile the model. </li>\n",
    "</ul>\n",
    "\n",
    "This will basically make a new model, that is exactly the same as the one that existed at the point in training when we saved the checkpoint.\n",
    "\n",
    "#### Example of Checkpoint\n",
    "\n",
    "We can see how this works by training a model a little, using the checkpoint callback, then loading the weights from the checkpoint and continuing training. I'll add a few layers and turn down the learning rate, so we can expect the training process to require a decent number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheck = keras.Sequential()\n",
    "modelCheck.add(Input(shape=(32, 32, 3)))\n",
    "modelCheck.add(Conv2D(64, (3, 3), activation='relu',  padding=\"same\"))\n",
    "modelCheck.add(MaxPooling2D((2, 2)))\n",
    "modelCheck.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelCheck.add(MaxPooling2D((2, 2)))\n",
    "modelCheck.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelCheck.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "modelCheck.add(Flatten())\n",
    "modelCheck.add(Dense(32, activation='relu'))\n",
    "modelCheck.add(Dense(10))\n",
    "modelCheck.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheck.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=metric_list)\n",
    "train_logCheck = modelCheck.fit(X_train, y_train, epochs=10, batch_size=BATCH_SIZE, validation_split=.3, verbose=1, callbacks=[stopping, checkpoint])\n",
    "test_evalCheck = modelCheck.evaluate(X_test, y_test, verbose=2)\n",
    "plot_loss(train_logCheck)\n",
    "plot_acc(train_logCheck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating Checkpoint Model\n",
    "\n",
    "We can now take the partially trained model that we just saved, recreate it into a new model, and continue training - or do any other model related activities that we had in mind. For this one I'll let the epochs be larger, so it can run a bit more. This training process will be a \"new\" one, but the starting point is where we left off with the checkpoint weights, in my trials I saw the first epoch ot have an accuracy of about 25%, the last epoch of the previous training to have an accuracy slightly under 50%, and our training here should pick up at somewhere around 50% and continue to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelCheckpoint' object has no attribute '_get_most_recently_modified_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mglob\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# There is a \"get_latest_checkpoint\" function in the keras documentation, but it doesn't work for me\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# locally. That is probably a better solution, but it appears to have some bug\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# There were a couple of post online about differences on mac/win/linux, but that's not certain. \u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#list_of_files = glob.glob(\"logs/weights/*.keras\") \u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#latest = max(list_of_files, key=os.path.getctime)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#print(latest)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m latest = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogs/weights/*.keras\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_most_recently_modified_file\u001b[49m()\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(latest)\n\u001b[32m     26\u001b[39m modelNew.load_weights(latest)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCheckpoint' object has no attribute '_get_most_recently_modified_file'"
     ]
    }
   ],
   "source": [
    "modelNew = keras.Sequential()\n",
    "modelNew.add(Input(shape=(32, 32, 3)))\n",
    "modelNew.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelNew.add(MaxPooling2D((2, 2)))\n",
    "modelNew.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelNew.add(MaxPooling2D((2, 2)))\n",
    "modelNew.add(Conv2D(256, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelNew.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "modelNew.add(Flatten())\n",
    "modelNew.add(Dense(32, activation='relu'))\n",
    "modelNew.add(Dense(10))\n",
    "\n",
    "# Load Weights\n",
    "#/Volumes/Storage/git_courses/semester/1222/3950/Intro_to_Machine_Learning_Student_Workbooks/logs/weightsimport os\n",
    "import glob\n",
    "\n",
    "# There is a \"get_latest_checkpoint\" function in the keras documentation, but it doesn't work for me\n",
    "# locally. That is probably a better solution, but it appears to have some bug\n",
    "# There were a couple of post online about differences on mac/win/linux, but that's not certain. \n",
    "list_of_files = glob.glob(\"logs/weights/*.keras\") \n",
    "latest = max(list_of_files, key=os.path.getctime)\n",
    "print(latest)\n",
    "modelNew.load_weights(latest)\n",
    "modelNew.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=.0001), metrics=metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logNew = modelNew.fit(X_train, y_train, epochs=15, batch_size=BATCH_SIZE, validation_split=.3, verbose=1, callbacks=[stopping, \n",
    "                                                                                                                           checkpoint,\n",
    "                                                                                                                           ])\n",
    "train_evalNew = modelNew.evaluate(X_train, y_train)\n",
    "test_evalNew = modelNew.evaluate(X_test, y_test, verbose=2)\n",
    "plot_loss(train_logNew)\n",
    "plot_acc(train_logNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating Checkpoint Model\n",
    "\n",
    "We can now take the partially trained model that we just saved, recreate it into a new model, and continue training - or do any other model related activities that we had in mind. For this one I'll let the epochs be larger, so it can run a bit more. This training process will be a \"new\" one, but the starting point is where we left off with the checkpoint weights, in my trials I saw the first epoch ot have an accuracy of about 25%, the last epoch of the previous training to have an accuracy slightly under 50%, and our training here should pick up at somewhere around 50% and continue to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Augmentation\n",
    "\n",
    "We can also add data augmentation to our model, this is a good way to increase the size of our dataset and improve the generalization of our model. We can do this by adding a layer to our model that will randomly rotate, flip, zoom, and shift the images in our dataset. This will make our model more robust to changes in the input data and help it to generalize better to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.1689 - loss: 2.2225\n",
      "Epoch 1: val_loss improved from inf to 2.06956, saving model to logs/weights/weights-improvement-20250327-130853.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 0.1700 - loss: 2.2206 - val_accuracy: 0.2241 - val_loss: 2.0696\n",
      "Epoch 2/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2891 - loss: 1.9832\n",
      "Epoch 2: val_loss did not improve from 2.06956\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.2895 - loss: 1.9821 - val_accuracy: 0.2439 - val_loss: 2.0913\n",
      "Epoch 3/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3325 - loss: 1.8614\n",
      "Epoch 3: val_loss improved from 2.06956 to 1.98698, saving model to logs/weights/weights-improvement-20250327-130853.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.3328 - loss: 1.8607 - val_accuracy: 0.3119 - val_loss: 1.9870\n",
      "Epoch 4/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.3549 - loss: 1.8052\n",
      "Epoch 4: val_loss improved from 1.98698 to 1.97062, saving model to logs/weights/weights-improvement-20250327-130853.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.3550 - loss: 1.8051 - val_accuracy: 0.3126 - val_loss: 1.9706\n",
      "Epoch 5/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.2635 - loss: 2.1600\n",
      "Epoch 5: val_loss improved from 1.97062 to 1.95049, saving model to logs/weights/weights-improvement-20250327-130853.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.2636 - loss: 2.1592 - val_accuracy: 0.3087 - val_loss: 1.9505\n",
      "Epoch 6/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3275 - loss: 1.8711\n",
      "Epoch 6: val_loss improved from 1.95049 to 1.82077, saving model to logs/weights/weights-improvement-20250327-130853.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.3279 - loss: 1.8703 - val_accuracy: 0.3679 - val_loss: 1.8208\n",
      "Epoch 7/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3520 - loss: 1.8419\n",
      "Epoch 7: val_loss did not improve from 1.82077\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.3511 - loss: 1.8464 - val_accuracy: 0.2228 - val_loss: 2.2244\n",
      "Epoch 8/15\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2534 - loss: 2.1310\n",
      "Epoch 8: val_loss did not improve from 1.82077\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.2545 - loss: 2.1271 - val_accuracy: 0.3577 - val_loss: 1.9044\n",
      "Epoch 9/15\n",
      "\u001b[1m 4/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.3428 - loss: 1.8623"
     ]
    }
   ],
   "source": [
    "agumentation_layers = Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(.2),\n",
    "    keras.layers.RandomZoom(.2),\n",
    "    keras.layers.RandomFlip(\"vertical\"),\n",
    "])\n",
    "model_aug = Sequential()\n",
    "\n",
    "model_aug.add(Input(shape=(32, 32, 3)))\n",
    "model_aug.add(agumentation_layers)\n",
    "model_aug.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model_aug.add(MaxPooling2D((2, 2)))\n",
    "model_aug.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model_aug.add(MaxPooling2D((2, 2)))\n",
    "model_aug.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model_aug.add(MaxPooling2D((2, 2)))\n",
    "model_aug.add(Flatten())\n",
    "model_aug.add(Dense(128, activation='relu'))\n",
    "model_aug.add(Dense(10))\n",
    "\n",
    "model_aug.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                    optimizer=keras.optimizers.Adam(), \n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "train_log_aug = model_aug.fit(X_train, y_train, epochs=15, batch_size=BATCH_SIZE, validation_split=.3, verbose=1, callbacks=[stopping, checkpoint])\n",
    "\n",
    "plot_loss(train_log_aug)\n",
    "plot_acc(train_log_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Implement a CNN model to classify the dataset. \n",
    "\n",
    "Try to:\n",
    "<ul>\n",
    "<li> Use a CNN model. </li>\n",
    "<li> Use a checkpoint to save the best model. </li>\n",
    "<li> Use tensorboard to monitor the training process. </li>\n",
    "<li> Use some hyperparameter tuning to find the best model. </li>\n",
    "</ul>\n",
    "\n",
    "Note - there's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n",
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import PIL \n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir_tmp = pathlib.Path(pathlib.Path.joinpath(data_dir, \"flower_photos\"))\n",
    "data_dir = data_dir_tmp\n",
    "\n",
    "#Flowers\n",
    "batch_size = BATCH_SIZE\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "modelFlow = Sequential()\n",
    "modelFlow.add(Input(shape=(img_height, img_width, 3)))\n",
    "modelFlow.add(Conv2D(32, 3, activation=\"relu\", padding=\"same\", kernel_regularizer=\"l2\"))\n",
    "modelFlow.add(MaxPooling2D())\n",
    "modelFlow.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_regularizer=\"l2\"))\n",
    "modelFlow.add(MaxPooling2D())\n",
    "modelFlow.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_regularizer=\"l2\"))\n",
    "modelFlow.add(MaxPooling2D())\n",
    "modelFlow.add(Flatten())\n",
    "modelFlow.add(Dense(128, activation=\"relu\"))\n",
    "modelFlow.add(Dense(5))\n",
    "modelFlow.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "modelFlow.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback_flower = keras.callbacks.TensorBoard(log_dir=LOGS+\"/flower\", write_graph=False, write_images=True)\n",
    "callbacksFlower = [stopping]\n",
    "if not HPARAM:\n",
    "  callbacksFlower.append(tensorboard_callback_flower)\n",
    "\n",
    "historyFlower = modelFlow.fit(train_ds, epochs=BASE_EPOCHS, validation_data=val_ds, callbacks=callbacksFlower)\n",
    "plot_loss(historyFlower)\n",
    "plot_acc(historyFlower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Callbacks\n",
    "\n",
    "We can also create custom callbacks, which can be used to do things like:\n",
    "<ul>\n",
    "<li> Save the model at certain intervals. </li>\n",
    "<li> Save the model if it is the best one. </li>\n",
    "<li> Change the learning rate. </li>\n",
    "<li> Log the training process. </li>\n",
    "<li> etc... </li>\n",
    "</ul>\n",
    "\n",
    "Callbacks are created by defining a new class that inherits from the keras.callbacks.Callback class, then overriding the methods that we want to use. Actions are triggered at certain points in the training process, the beginnings and ends of things like training, epochs, and batches. We can do almost anything in here, common tasks are saving training progress, logging custom data, and managing the learning rate. If there are any inputs like log file paths, test data, etc... they can be passed in as arguments to the constructor and stored as variables in the callback object.\n",
    "\n",
    "#### Confusion Matrix Logger\n",
    "\n",
    "This is a custom callback that will log the confusion matrix at the end of each epoch. In this one we display an image - to show images we need to first convert the confusion matrix to an image, then convert it to a tensor, then log it. That's something that I'd recommend looking up as needed, it is shown in the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(self.y, axis=1)\n",
    "        cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        #print(cm)\n",
    "        figure = plt.figure(figsize=(8, 8))\n",
    "        ax = figure.add_subplot(111)\n",
    "        ax.matshow(cm, cmap='coolwarm', alpha=0.8)\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(x=j, y=i, s=cm[i, j], va='center', ha='center')\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "\n",
    "        # Convert the plot to an image tensor\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        # Log the image to TensorBoard\n",
    "        with tf.summary.create_file_writer(LOGS).as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New small model - we can see improvements\n",
    "modelSmall = keras.Sequential()\n",
    "modelSmall.add(Input(shape=(32, 32, 3)))\n",
    "modelSmall.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelSmall.add(MaxPooling2D((2, 2)))\n",
    "modelSmall.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\"))\n",
    "modelSmall.add(MaxPooling2D((2, 2)))\n",
    "modelSmall.add(Flatten())\n",
    "modelSmall.add(Dense(128, activation='relu'))\n",
    "modelSmall.add(Dense(10))\n",
    "\n",
    "modelSmall.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                     optimizer=keras.optimizers.Adam(learning_rate=.00001),\n",
    "                     metrics=metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback3 = keras.callbacks.TensorBoard(log_dir=LOGS+\"/small_model\", \n",
    "                                                    write_graph=False, \n",
    "                                                    write_images=True)\n",
    "confusion_callback = ConfusionMatrixCallback(X_test, y_test)\n",
    "callbacks3 = [stopping, confusion_callback]\n",
    "if HPARAM:\n",
    "  callbacks3.append(tensorboard_callback3)\n",
    "historySmall = modelSmall.fit(X_train, y_train, \n",
    "                              epochs=50, \n",
    "                              validation_split=.3, \n",
    "                              callbacks=callbacks3, \n",
    "                              batch_size=BATCH_SIZE)\n",
    "\n",
    "plot_loss(historySmall)\n",
    "plot_acc(historySmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the flower data from the previous exercise and build another model. Use this callback, then try to make or modify your own and use it in the tensorboard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mar_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
